# TellCo Data Analysis and Business Insight

This project is designed to perform a detailed analysis of TellCo's data to identify opportunities for growth and make a recommendation on whether TellCo is worth buying or selling. The analysis involves cleaning and preprocessing the data, performing correlation analysis, and dimensionality reduction using Principal Component Analysis (PCA).

## Table of Contents

- [Introduction]
- [Setup]
- [Usage]
- [Dependencies]

## Introduction

This project aims to help a wealthy investor analyze the data generated by TellCo, a mobile service provider in the Republic of Pefkakia. The goal is to understand the fundamentals of the business and identify opportunities to drive profitability by focusing on specific products or services. The insights will be delivered through a detailed report and an interactive web-based dashboard.

## Setup

Follow these steps to set up the project:

1. **Clone the repository**:
    git clone https://github.com/your-repository/tellco-data-analysis.git
    cd tellco-data-analysis
    ```

2. **Create a virtual environment** (optional but recommended):
    python -m venv venv
    source venv/bin/activate  # On Windows use `venv\Scripts\activate`
    ```

3. **Install dependencies**:
    pip install -r requirements.txt
    ```

4. **Set up environment variables**:
    Create a `.env` file in the root directory of the project and add your database credentials:
    ```
    DB_HOST=your_db_host
    DB_PORT=your_db_port
    DB_NAME=your_db_name
    DB_USER=your_db_user
    DB_PASSWORD=your_db_password
    ```

## Usage

### Run the Analysis

To run the analysis, execute the main script which performs the following steps:
1. Load and preprocess the data
2. Perform EDA

Example usage in your analysis notebook:
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sqlalchemy import create_engine
import os
from dotenv import load_dotenv
from correlational_anal import correlation_analysis
from dimensionality_reduction import dimensionality_reduction

# Load environment variables from the .env file
load_dotenv()

# Retrieve the environment variables
DB_HOST = os.getenv("DB_HOST")
DB_PORT = os.getenv("DB_PORT")
DB_NAME = os.getenv("DB_NAME")
DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")

# Construct the connection string
connection_string = f"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"

# Create the engine
engine = create_engine(connection_string)

# Update the query with exact column names and without table prefix
query = """
SELECT "MSISDN/Number" AS user,
       "Bearer Id",
       "Dur. (ms)",
       "Total DL (Bytes)",
       "Total UL (Bytes)",
       "Social Media DL (Bytes)",
       "Google DL (Bytes)",
       "Email DL (Bytes)",
       "Youtube DL (Bytes)",
       "Netflix DL (Bytes)",
       "Gaming DL (Bytes)",
       "Other DL (Bytes)"
FROM xdr_data;
"""

# Load the cleaned data from the database
data = pd.read_sql_query(query, engine)

#### Dependencies
The project dependencies are listed in the requirements.txt file. To install them, run:
pip install -r requirements.txt